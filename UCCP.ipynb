{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f554b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *\n",
    "\n",
    "mat = scipy.io.loadmat('Data_sets\\Synthesis_MS_train_test\\MS.mat')\n",
    "Train = mat['MS']\n",
    "mat = scipy.io.loadmat('Data_sets\\Synthesis_MS_train_test\\Verify.mat')\n",
    "Verify = mat['Verify']\n",
    "dt = 0.00025\n",
    "Fs = 1/dt\n",
    "f_min=1e-8\n",
    "f_max = Fs/4\n",
    "fo = 5\n",
    "nf = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff250075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model_def import *\n",
    "\n",
    "\n",
    "INPUT_SIZE1 = np.shape(Train)[1]\n",
    "INPUT_SIZE2 = np.shape(Train)[0]\n",
    "INPUT_SIZE3 = nf\n",
    "\n",
    "input_img = Input(shape=(INPUT_SIZE2, INPUT_SIZE3, 1))\n",
    "\n",
    "D1 = int(nf/128)\n",
    "D2 = int(D1*2)\n",
    "D3 = int(D1*4)\n",
    "D4 = int(D1*8)\n",
    "D5 = int(D1*16)\n",
    "D6 = int(D1*32)\n",
    "D7 = int(D1*64)\n",
    "D8 = int(D1*128)\n",
    "latent_dim = D4\n",
    "\n",
    "kernel_size = 5, 5\n",
    "\n",
    "encoded1 = CBA(input_img, D1, kernel_size, strides = (1, 4), padding = 'same')\n",
    "# encoded1 = Res_CNN_block(encoded1, filters=D1, kernel_size=3, padding='same', activation='relu', drop_rate=0.1)\n",
    "#encoded1 = Dropout(0.5)(encoded1)\n",
    "\n",
    "encoded2 = CBA(encoded1, D2, kernel_size, strides = (1, 4), padding = 'same')\n",
    "# encoded2 = Res_CNN_block(encoded2, filters=D2, kernel_size=3, padding='same', activation='relu', drop_rate=0.1)\n",
    "#encoded2 = Dropout(0.5)(encoded2)\n",
    "\n",
    "encoded3 = CBA(encoded2, D3, kernel_size, strides = (1, 4), padding = 'same')\n",
    "# encoded3 = Res_CNN_block(encoded3, filters=D3, kernel_size=3, padding='same', activation='relu', drop_rate=0.1)\n",
    "#encoded3 = Dropout(0.5)(encoded3)\n",
    "\n",
    "encoded4 = CBA(encoded3, D4, kernel_size, strides = (1, 4), padding = 'same')\n",
    "# encoded4 = Res_CNN_block(encoded4, filters=D4, kernel_size=3, padding='same', activation='relu', drop_rate=0.1)\n",
    "#encoded4 = Dropout(0.5)(encoded4)\n",
    "\n",
    "Xm = Reshape((encoded4.shape[1], D4))(encoded4)\n",
    "\n",
    "Xm = LSTM(D4, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(Xm)\n",
    "# Xm = BiLSTM_block(D4, drop_rate=0.1, padding='same', inpR=Xm)\n",
    "# Xm = Attention_Global()(Xm)\n",
    "Xm, weightd_D0 = Global_attention(drop_rate=0.1, width=None, name='attentionD0', inpC=Xm) \n",
    "\n",
    "# Xm = LSTM(D4, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(Xm)\n",
    "Xm, weightd_P = SeqSelfAttention(return_attention=True, attention_width= 3, name='attention_P')(Xm)\n",
    "\n",
    "Xm = Reshape((encoded4.shape[1], encoded4.shape[2], D4))(Xm)\n",
    "# encoded5 = channel_attention(encoded4, ratio=8)\n",
    "\n",
    "# Decoder\n",
    "decoded1 = CTBA(Xm, D4, kernel_size, strides = (1, 4), padding = 'same')\n",
    "# decoded1 = Res_CNN_block(decoded1, filters=D4, kernel_size=3, padding='same', activation='relu', drop_rate=0.1)\n",
    "\n",
    "decoded2 = CTBA(decoded1, D3, kernel_size, strides = (1, 4), padding = 'same')\n",
    "# decoded2 = Res_CNN_block(decoded2, filters=D3, kernel_size=3, padding='same', activation='relu', drop_rate=0.1)\n",
    "\n",
    "decoded3 = CTBA(decoded2, D2, kernel_size, strides = (1, 4), padding = 'same')\n",
    "# decoded3 = Res_CNN_block(decoded3, filters=D2, kernel_size=3, padding='same', activation='relu', drop_rate=0.1)\n",
    "\n",
    "decoded4 = CTBA(decoded3, D1, kernel_size, strides = (1, 4), padding = 'same')\n",
    "# decoded4 = Res_CNN_block(decoded4, filters=D1, kernel_size=3, padding='same', activation='relu', drop_rate=0.1)\n",
    "\n",
    "decoded = Conv2D(1, kernel_size, strides = (1,1), padding = 'same', activation='linear', name = 'visualized_layer')(decoded4)\n",
    "\n",
    "encoder = Model(input_img, Xm, name='encoder')\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "sgd = optimizers.Adam(learning_rate=0.001, decay=0.0, beta_1=0.9, beta_2=0.999, epsilon=1e-08, amsgrad=False)\n",
    "autoencoder.compile(optimizer=sgd, loss='mse')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f201d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "\n",
    "Train1 = np.transpose(Train)\n",
    "scal = np.zeros((np.shape(Train1)[0], np.shape(Train1)[1], nf))\n",
    "for ix in range(0, np.shape(Train1)[0]):\n",
    "    sig0 = Train1[ix, :]\n",
    "    temp0 = cwt(sig0, dt, 4, f_min, f_max, nf=nf,  wl='morlet')\n",
    "    temp0 = np.abs(temp0)\n",
    "    scal[ix] = np.transpose(temp0)\n",
    "\n",
    "Verify_1 = np.transpose(Verify)\n",
    "Verify_cwt = np.zeros((np.shape(Verify_1)[0], np.shape(Verify_1)[1], nf))\n",
    "for ix in range(0, np.shape(Verify_1)[0]):\n",
    "    sig0 = Verify_1[ix, :]\n",
    "    temp0 = cwt(sig0, dt, 4, f_min, f_max, nf=nf,  wl='morlet')\n",
    "    temp0 = np.abs(temp0)\n",
    "    Verify_cwt[ix] = np.transpose(temp0)\n",
    "scal1 = np.reshape(scal, (np.shape(scal)[0], np.shape(scal)[1], np.shape(scal)[2], 1))\n",
    "Verify_cwt1 = np.reshape(Verify_cwt, (np.shape(Verify_cwt)[0], np.shape(Verify_cwt)[1], np.shape(Verify_cwt)[2], 1))\n",
    "\n",
    "autoencoder.fit(scal1, scal1, epochs=5, batch_size=batch, shuffle=False, verbose=1)  # validation_data=(Verify_cwt1, Verify_cwt1),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ddbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('Data_sets\\Synthesis_MS_train_test\\test.mat')\n",
    "Test = mat['test']\n",
    "\n",
    "Test1 = np.transpose(Test)\n",
    "Test_cwt = np.zeros((np.shape(Test1)[0], np.shape(Test1)[1], nf))\n",
    "for ix in range(0, np.shape(Test1)[0]):\n",
    "    sig0 = Test1[ix, :]\n",
    "    temp0 = cwt(sig0, dt, 4, f_min, f_max, nf=nf,  wl='morlet')\n",
    "    temp0 = np.abs(temp0)\n",
    "    Test_cwt[ix] = np.transpose(temp0)\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MaxAbsScaler()\n",
    "Test1 = min_max_scaler.fit_transform(Test1)\n",
    "clabelf, labelproposed = FCM_predict(Test1, encoder, Test_cwt, nf, D4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e40294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TF2.5] *",
   "language": "python",
   "name": "conda-env-TF2.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
